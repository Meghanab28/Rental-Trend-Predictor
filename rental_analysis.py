# -*- coding: utf-8 -*-
"""Rental Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NA44UrxhH48S-HYX1fXPw8MCcUpYEOkV
"""

#1) Importing all the necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
# Load the dataset
df = pd.read_csv("/content/House_Rent_Dataset.csv")
# Display the first few rows
print(df.head())

# 2)Loading the data set

print("Loading dataset...")
df = pd.read_csv("/content/House_Rent_Dataset.csv")
print("Dataset loaded successfully!")

# 3)Exploring the dataset
print("\nExploring the dataset:")
print(f"Dataset shape: {df.shape}")
print("\nDataset information:")
print(df.info())

print("\nChecking for missing values:")
print(df.isnull().sum())

print("\nDescriptive statistics:")
print(df.describe())

print("\nCities in the dataset:")
city_counts = df['City'].value_counts()
print(city_counts)

print("\nRent distribution by City:")
for city in df['City'].unique():
    city_data = df[df['City'] == city]
    print(f"{city}: Min: {city_data['Rent'].min()}, Max: {city_data['Rent'].max()}, Mean: {city_data['Rent'].mean():.2f}, Median: {city_data['Rent'].median()}")

print("\nChecking for outliers in Rent...")
Q1 = df['Rent'].quantile(0.25)
Q3 = df['Rent'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
print(f"Lower bound: {lower_bound}")
print(f"Upper bound: {upper_bound}")
outliers = df[(df['Rent'] < lower_bound) | (df['Rent'] > upper_bound)]
print(f"Number of outliers: {len(outliers)}")

print("\nApplying log transformation to Rent...")
df['Log_Rent'] = np.log1p(df['Rent'])

# 4)Preprocessing the data (feature engineering + encoding)
import re
print("\nPreprocessing data...")

# Extract number of BHK (Bedrooms, Hall, Kitchen)
# Already present in the dataset as 'BHK'
# Extract area in square feet from Size column
def extract_numeric_size(size_val):
    if pd.isna(size_val):
        return np.nan
    # Check if it's already a number
    if isinstance(size_val, (int, float)):
        return float(size_val)
    # Otherwise assume it's a string and extract the first number
    try:
        return float(size_val.split()[0])
    except (AttributeError, ValueError, IndexError):
        # If there's any issue, return NaN
        return np.nan

df['Size_Numeric'] = df['Size'].apply(extract_numeric_size)

# Extract floor information
def extract_floor_info(floor_str):
    if pd.isna(floor_str):
        return 0, 0

    # Handle "Ground out of X" case
    if floor_str.startswith('Ground'):
        current_floor = 0
        try:
            total_floors = int(re.search(r'out of (\d+)', floor_str).group(1))
        except (AttributeError, ValueError):
            total_floors = 0
        return current_floor, total_floors

    # Handle "X out of Y" case
    parts = floor_str.split(' out of ')
    try:
        current_floor = int(parts[0])
    except ValueError:
        current_floor = 0

    try:
        total_floors = int(parts[1])
    except (IndexError, ValueError):
        total_floors = 0

    return current_floor, total_floors

df['Current_Floor'], df['Total_Floors'] = zip(*df['Floor'].apply(extract_floor_info))
df['Floor_Ratio'] = df['Current_Floor'] / df['Total_Floors'].replace(0, 1)

# Process Area Type
# Keep as categorical

# Create features from Point of Contact
df['Point_of_Contact_Owner'] = df['Point of Contact'].apply(lambda x: 1 if x == 'Owner' else 0)

# Print the processed dataframe
print("\nPreprocessed data:")
print(df.head())

#Split the data
# Sort the DataFrame by 'Posted On'
df = df.sort_values(by='Posted On')

# Define features (X) and target (y)
X = df.drop('Rent', axis=1)
y = df['Rent'] # Changed df_encoded to df


#5) Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=False)

# Print the shapes of the resulting sets
print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)
print("X_test shape:", X_test.shape)
print("y_test shape:", y_test.shape)

# Train-Test Split
from sklearn.model_selection import train_test_split # Import train_test_split

print("Splitting data into train and test sets...")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Training set size: {X_train.shape}")
print(f"Testing set size: {X_test.shape}\n")

# 6. Train Linear Regression Model
# Impute missing values using SimpleImputer
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# ... (your existing code for loading and preprocessing data) ...

# Create a SimpleImputer instance to replace NaNs with the mean
imputer = SimpleImputer(strategy='mean')

# Fit the imputer to your training data and transform both train and test sets
X_train = imputer.fit_transform(X_train)
X_test = imputer.transform(X_test)

# Initialize and train the model
model = LinearRegression()
model.fit(X_train, y_train)

print("Linear Regression model trained successfully!")

# 7. Model Evaluation Metrics

from sklearn.metrics import mean_squared_error, r2_score

# Predict on the test set
y_pred = model.predict(X_test)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate RÂ² Score
r2 = r2_score(y_test, y_pred)

# Print evaluation results
print(f"ðŸ“ˆ Mean Squared Error (MSE): {mse:.2f}")
print(f"ðŸ“ˆ RÂ² Score: {r2:.2f}")

# 8. Visualization of the data

import matplotlib.pyplot as plt
import seaborn as sns

# 8.1 Distribution of Rent Prices
# Plot the distribution of Rent to understand overall spread
plt.figure(figsize=(8,5))
sns.histplot(df['Rent'], bins=50, kde=True, color='skyblue')  # kde=True adds smooth curve
plt.title('Distribution of Rent Prices')
plt.xlabel('Rent')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

# 8.2 Average Rent by City
# Plot average rent prices for each city

# First calculate average rent by city
avg_rent_city = df.groupby('City')['Rent'].mean()

# Convert to DataFrame for cleaner seaborn plotting
avg_rent_city_df = avg_rent_city.reset_index()
avg_rent_city_df.columns = ['City', 'Average_Rent']

# Now plot using seaborn barplot
plt.figure(figsize=(8,5))
sns.barplot(data=avg_rent_city_df, x='City', y='Average_Rent', hue='City', palette='viridis', dodge=False, legend=False)  # dodge=False to avoid thin bars, legend=False to hide legend
plt.title('Average Rent by City')
plt.xlabel('City')
plt.ylabel('Average Rent')
plt.grid(True)
plt.show()

# 8.3 Actual vs Predicted Rent
# Scatter plot to compare actual vs predicted rent prices
plt.figure(figsize=(8,5))
plt.scatter(y_test, y_pred, alpha=0.7, color='coral')
plt.title('Actual vs Predicted Rent')
plt.xlabel('Actual Rent')
plt.ylabel('Predicted Rent')
plt.grid(True)
plt.show()